{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "from datasets import load_from_disk\n",
    "\n",
    "# Path to the clients_dataset folder\n",
    "clients_dataset_path = \"../src/clients_dataset\"\n",
    "\n",
    "# Dictionary to store dataset info for each client.\n",
    "# The structure will be:\n",
    "# {\n",
    "#     \"client_name\": {\n",
    "#         \"dataset_name\": {\n",
    "#             \"dataset_size\": <size>,\n",
    "#             \"label_distribution\": <Counter object>\n",
    "#         },\n",
    "#         ...\n",
    "#     },\n",
    "#     ...\n",
    "# }\n",
    "client_data_info = {}\n",
    "\n",
    "\n",
    "def load_data_info(client_folder):\n",
    "    \"\"\"\n",
    "    Loads each dataset in the client_folder, counts label distribution and stores dataset size.\n",
    "    \"\"\"\n",
    "    distribution_info = {}\n",
    "    with os.scandir(client_folder) as entries:\n",
    "        for entry in entries:\n",
    "            if entry.is_dir():\n",
    "                dataset_path = entry.path\n",
    "                data = load_from_disk(dataset_path)\n",
    "                dataset_size = len(data)\n",
    "                print(f\"Processing {entry.name} (dataset size: {dataset_size})\")\n",
    "                # Count labels efficiently by directly accessing the column.\n",
    "                label_counts = Counter(data[\"label\"])\n",
    "                distribution_info[entry.name] = {\n",
    "                    \"dataset_size\": dataset_size,\n",
    "                    \"label_distribution\": label_counts,\n",
    "                }\n",
    "    return distribution_info\n",
    "\n",
    "\n",
    "# Process each client and store the info.\n",
    "with os.scandir(clients_dataset_path) as clients:\n",
    "    for client in clients:\n",
    "        if client.is_dir():\n",
    "            print(f\"Processing client: {client.name}\")\n",
    "            client_data_info[client.name] = load_data_info(client.path)\n",
    "            print()  # Blank line for readability\n",
    "\n",
    "# Now, client_data_info holds both the dataset sizes and label distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# First, get the union of all dataset keys across clients (excluding 'clean_train_data')\n",
    "all_dataset_keys = set()\n",
    "for datasets in client_data_info.values():\n",
    "    for key in datasets.keys():\n",
    "        if key != \"clean_train_data\":\n",
    "            all_dataset_keys.add(key)\n",
    "all_dataset_keys = sorted(all_dataset_keys)  # sort for consistency\n",
    "\n",
    "# Create a fixed color mapping for each dataset key using a colormap.\n",
    "colors_list = plt.cm.tab10(np.linspace(0, 1, len(all_dataset_keys) + 3))\n",
    "color_mapping = dict(zip(all_dataset_keys, colors_list))\n",
    "\n",
    "# Compute the global maximum dataset size across all clients (excluding 'clean_train_data')\n",
    "global_max = 0\n",
    "for datasets in client_data_info.values():\n",
    "    for key, info in datasets.items():\n",
    "        if key != \"clean_train_data\":\n",
    "            global_max = max(global_max, info[\"dataset_size\"])\n",
    "\n",
    "# Determine the number of clients to create one subplot per client in a single row.\n",
    "num_clients = len(client_data_info)\n",
    "fig, axes = plt.subplots(ncols=num_clients, figsize=(10 * num_clients, 8))\n",
    "\n",
    "# Ensure axes is always iterable (even if there's only one client)\n",
    "if num_clients == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "# Loop through each client and plot the dataset sizes.\n",
    "for ax, (client, datasets) in zip(axes, client_data_info.items()):\n",
    "    # Exclude 'clean_train_data' from the dataset keys.\n",
    "    dataset_names = [k for k in datasets.keys() if k != \"clean_train_data\"]\n",
    "    sizes = [datasets[ds][\"dataset_size\"] for ds in dataset_names]\n",
    "\n",
    "    # Use the fixed color mapping for each dataset key.\n",
    "    colors = [color_mapping[ds] for ds in dataset_names]\n",
    "\n",
    "    # Create bar chart using the assigned colors.\n",
    "    ax.bar(dataset_names, sizes, color=colors)\n",
    "\n",
    "    # Increase font sizes for title and axis labels.\n",
    "    ax.set_title(f\"Dataset sizes for Client {client.split('_')[-1]}\", fontsize=24)\n",
    "    ax.set_ylabel(\"Size\", fontsize=24)\n",
    "    ax.tick_params(axis=\"both\", labelsize=24)\n",
    "\n",
    "    # Use the global maximum for a consistent y-axis scale.\n",
    "    ax.set_ylim(0, global_max * 1.2)\n",
    "\n",
    "    # Add text labels on top of each bar.\n",
    "    for i, size in enumerate(sizes):\n",
    "        ax.text(\n",
    "            i,\n",
    "            size + 0.05 * global_max,\n",
    "            str(size),\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=24,\n",
    "        )\n",
    "\n",
    "    # Set x-axis tick labels with individual colors.\n",
    "    labels = [name.split(\"_\")[0].capitalize() for name in dataset_names]\n",
    "    ax.set_xticks(np.arange(len(dataset_names)))\n",
    "    tick_labels = ax.set_xticklabels(labels, fontsize=24)\n",
    "    for tick, ds in zip(ax.get_xticklabels(), dataset_names):\n",
    "        tick.set_color(color_mapping[ds])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Increase font sizes globally\n",
    "plt.rcParams.update(\n",
    "    {\n",
    "        \"font.size\": 17,  # default text size\n",
    "        \"axes.titlesize\": 19,  # title font size\n",
    "        \"axes.labelsize\": 17,  # axis label font size\n",
    "        \"xtick.labelsize\": 15,  # x-tick label size\n",
    "        \"ytick.labelsize\": 15,  # y-tick label size\n",
    "        \"legend.fontsize\": 15,  # legend font size\n",
    "    }\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# Graph 1: For each client, plot train_data, val_data (test) distributions,\n",
    "# and optionally clean_train_data if present.\n",
    "# -------------------------------\n",
    "\n",
    "# Use the new dictionary created in the previous cell.\n",
    "num_clients = len(client_data_info)\n",
    "fig, axes = plt.subplots(1, num_clients, figsize=(5 * num_clients, 5), sharey=True)\n",
    "\n",
    "# Ensure axes is iterable when there's only one client.\n",
    "if num_clients == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "# Loop through each client (sorted for consistency).\n",
    "for ax, (client, splits) in zip(axes, sorted(client_data_info.items())):\n",
    "    # Retrieve label distributions for each split.\n",
    "    train_counter = splits.get(\"train_data\", {}).get(\"label_distribution\", {})\n",
    "    test_counter = splits.get(\"val_data\", {}).get(\"label_distribution\", {})\n",
    "    clean_train = splits.get(\"clean_train_data\", {}).get(\"label_distribution\", {})\n",
    "    has_clean = bool(clean_train)\n",
    "\n",
    "    # Determine the union of classes from all available splits.\n",
    "    keys = sorted(\n",
    "        set(train_counter)\n",
    "        | set(test_counter)\n",
    "        | (set(clean_train) if has_clean else set())\n",
    "    )\n",
    "\n",
    "    # Get counts for each class (defaulting to 0 if missing).\n",
    "    train_vals = [train_counter.get(k, 0) for k in keys]\n",
    "    test_vals = [test_counter.get(k, 0) for k in keys]\n",
    "    if has_clean:\n",
    "        clean_train_vals = [clean_train.get(k, 0) for k in keys]\n",
    "\n",
    "    x = np.arange(len(keys))\n",
    "    if has_clean:\n",
    "        width = 0.25  # width for each bar\n",
    "        ax.bar(x - width, train_vals, width, label=\"Train\")\n",
    "        ax.bar(x, test_vals, width, label=\"Test\")\n",
    "        ax.bar(x + width, clean_train_vals, width, label=\"Clean Train\")\n",
    "    else:\n",
    "        width = 0.35  # width for each bar\n",
    "        ax.bar(x - width / 2, train_vals, width, label=\"Train\")\n",
    "        ax.bar(x + width / 2, test_vals, width, label=\"Test\")\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(keys)\n",
    "    ax.set_title(f\"Client {client.split('_')[-1]}\")\n",
    "    ax.set_xlabel(\"Class\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "from numpy import imag\n",
    "\n",
    "\n",
    "# Path to the clients_dataset folder\n",
    "clients_poisoned_dataset_path = \"../src/clients_dataset/client_0/poisoned_data\"\n",
    "poisoned_data = load_from_disk(clients_poisoned_dataset_path)\n",
    "\n",
    "image = poisoned_data[0][\"image\"]\n",
    "label = poisoned_data[0][\"label\"]\n",
    "\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "plt.title(f\"Label: {label}\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
